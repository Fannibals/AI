## Introduction to Planning
## How to Describe Arbitrary Search Problems

### 1. Autonomous Behaviour in AI

+ the key problem is to select the action to do next. -- control problem
  - Programming-based: specify control by hand
    - Advantage: domain-knowledge easy to express
    - Disadvantage: cannot deal with situations not anticipated by programmer
  - Learning-based: learn control from experience
    - Unsupervised  
      - Unsupervised learning is where you only have input data (X) and no corresponding output variables
      - Clustering and Association
    - Supervised
      - Supervised learning is where you have input variables (x) and an output variable (Y) and you use an algorithm to learn the mapping function from the input to the output. Y = f(X)
      - Classification and Regression
    - Evolutionary 
    - Advantage: does not require much knowledge in principle
    - Disadvantage: in practice, hard to know which features to learn, and is slow
 
  - Model-based: Specify problem by hand, derive control automatically
    - Advantage: powerful, Quick, flexible & clear, Intelligent & domain-independent
    - Disadvantage: efficiency loss
  - |Classical Planning| Conformant Planning | planning withMarkov Decision Processes| Partially Observable MDPs| 
    | ---|---|---|---|
    |finite and discrete state space S |-  |-  |- | 
    |a **known initial state s0 ∈ S** |a set of possible initial state S0 ∈ S  |- | -| -|
    |a set SG ⊆ S of goal states | -| -| -| -|
    |actions A(s) ⊆ A applicable in each s ∈ S | -| -| -| - |
    |a deterministic transition function s' = f(a,s) for a ∈ A(s) |a non-deterministic transition function F(a,s) ⊆ S for a ∈ A(s) |transition probabilities Pa(s0|s) for s ∈ S and a ∈ A(s) | -|- |
    |positive action costs c(a,s) | -|- |- |- |
    |a solution is an action sequence that maps So to Sg, optimal if it minimizes sum of action costs| must achieve the goal for any possible initial state and transition| Solutions are functions mapping states into actions| -| 
    
  - for a problem:
    - Agent A must reach G, moving one cell at a time in KNOWN map
    
    - | actions| location| planning model|
      |:---:|:---:|:---:|
      |deterministic| initial location known| Classcial planning|
      |stochastic| location observable| planning with MDP|
      |stochastic| location partially observable| POMDP|
